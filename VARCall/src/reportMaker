#!/usr/bin/python
# -*- coding: iso-8859-1 -*-
import os, sys, time
import argparse
import subprocess 
import uuid


__doc__="""
Make a PDF report from the log file generated by the VarCall workflow.
"""

def get_parser():
	"""
	Parse arguments
	@return: arguments list
	@rtype: parser object
	"""

	parser = argparse.ArgumentParser(description='Make a PDF report from the log file generated by the VarCall workflow.')

	parser.add_argument('-i', action="store", dest='logFile', 
						type=str, required=True, help='log file (REQUIRED)')

	parser.add_argument('-o', action="store", dest='output', 
						type=str, default='output', help='output prefix (default:output)')

	return parser



def texHeader(texFile):
	"""
	Write the header of the LaTeX output file
	@param texFile : path of the output LaTeX file 
	@type texFile : string
	"""

	tFile = open(texFile, 'w')
	tFile.write("\documentclass{article}\n")
	tFile.write("\usepackage[superscript]{cite} \n")
	tFile.write("\usepackage{graphicx}\n")
	tFile.write("\usepackage{relsize,setspace}\n")
	tFile.write("\usepackage{url}\n")
	tFile.write("\usepackage{listings}\n")
	tFile.write("\usepackage{fancyhdr}\n")
	tFile.write("\usepackage[T1]{fontenc}\n")
	tFile.write("\usepackage{tgpagella}\n")
	tFile.write("\usepackage{xcolor}\n")
	tFile.write("\pagestyle{fancy}\n")
	tFile.write("\usepackage[pdftex,bookmarks,pdfpagemode=UseOutlines,\
		pdfauthor={Arnaud Felten},pdftitle={VarCall analysis}]{hyperref}\n")
	tFile.write("\\newcommand{\code}[1]{\\texttt{\smaller #1}}\n")
	tFile.write("\\newcommand{\R}{{\normalfont\\textsf{R}}{}}\n")
	tFile.write("\parskip 1.25ex\n")
	tFile.write("\parindent 0ex\n")
	tFile.write("\\textwidth 6.75in\n")
	tFile.write("\\textheight 9.25in\n")
	tFile.write("\\topmargin -.875in\n")
	tFile.write("\oddsidemargin -.125in\n")
	tFile.write("\evensidemargin -.125in\n")
	tFile.write("\DeclareGraphicsExtensions{.pdf, .jpg, .png}\n")
	tFile.write("\setkeys{Gin}{width=0.85\textwidth}\n")
	tFile.write("\\title{VarCall analysis report}\n")
	tFile.write("\\author{\\textbf{Anses} \\\\ \smaller Laboratory of food safety \\\\ \smaller GAMeR team \\\\ \n")
	#tFile.write("\\texttt{arnaud.felten@anses.fr}}\n")
	tFile.write("}\n")
	tFile.write("\date{\smaller \\today}\n")
	tFile.write("\\begin{document}\n")
	tFile.write("\maketitle\n")
	tFile.write("\n")

	tFile.close()


def writeVarCallCommand(lines, texFile):
	"""
	Write the VarCall command in the LaTeX output file
	@param lines : lines of the log file 
	@type lines : list
	@param texFile : path of the output LaTeX file 
	@type texFile : string
	"""

	texFile.write("\\fbox{\parbox{17cm}{\n")

	for line in lines[1:] :

		line = line.rstrip()

		if "VarCall" in line :
			texFile.write("\\textbf{VarCall}")
		elif line[0] == '-':
			texFile.write("\\\\ \n")
			arg = line.split(' ')
			texFile.write("\\textbf{" + arg[0] + "} ")

			if len(arg)==2 :
				arg[1] = arg[1].replace("/","{/}")
				arg[1] = arg[1].replace("_","\_")
				texFile.write(arg[1])

			else :
				for element in arg[1:]:
					element = element.replace("/","{/}")
					element = element.replace("_","\_")	
					texFile.write("\\\\ \n" + element)

			#texFile.write(line)	
		else:
			break

	texFile.write("}}\n")			


def extractReadStatistics(lines):
	"""
	Extract reads statistics from the log file lines.
	@param lines : lines of the log file 
	@type lines : list
	@return: dictionnary with sample name in key and for value an other \
	dictionnary with the number of reads before and after trimming, \
	the number of reads mapped and properly paired, \
	and the deep and breadth coverage.
	@rtype: dictionnary 
	"""

	dicoResult = {}

	for line in lines :

		if(line.split(" ")[0]=="BAMmaker"):
			readsName = line.split(" ")[4]
			readsName = readsName.split('.')[0]
			if('_R1' in readsName):
				readsName = readsName.replace('_R1','')
			elif('_1' in readsName):
				readsName = readsName.replace('_R1','')	
			readsName = readsName.replace("_","\_")	
			dicoResult[readsName] = {}
			
		if("Number of reads before trimming" in line):
			nbReads = line.split(' ')[6]
			nbReads = nbReads.rstrip()
			dicoResult[readsName]["reads"] = nbReads

		if("(QC-passed reads + QC-failed reads)" in line):
			trimming = line.split(' ')[0]
			dicoResult[readsName]["trimming"] = trimming	
			
		if(" mapped (" in line):
			mapped = line.split(' ')[0]
			dicoResult[readsName]["mapped"] = mapped	

		if("properly paired" in line):
			paired = line.split(' ')[0]
			dicoResult[readsName]["paired"] = paired
			
		if("Deep coverage" in line):
			deep = line.split(' ')[3]
			deep = deep.rstrip()
			dicoResult[readsName]["deep cov."] = deep	

		if("Breadth coverage" in line):
			breadth = line.split(' ')[3]
			breadth = breadth.rstrip()
			breadth = breadth.replace('%','\%')
			dicoResult[readsName]["breadth cov."] = breadth

	return dicoResult							


def workdir():
	"""
	Find working directory and transformed it for write in latex file
	@return: working directory transformed
	@rtype: string
	"""

	workdir = os.getcwd()
	workdir = workdir.replace("/","{/}")
	workdir = workdir.replace("_","\_")

	return workdir


def version():
	"""
	Find all version of all tools used by VarCall
	@return: dictionnary with program name as key and version as value.
	@rtype: dictionnary
	"""

	tmpFile = str(uuid.uuid4()) + '.tmp'
	dicoVersion = {}

	#bwa
	os.system("bwa > " + tmpFile + " 2>&1")
	f=open(tmpFile,'r')
	lines=f.readlines()
	f.close()
	version = lines[2].split(' ')[1].rstrip()
	dicoVersion['bwa'] = version

	#samtools
	os.system("samtools > " + tmpFile + " 2>&1")
	f=open(tmpFile,'r')
	lines=f.readlines()
	f.close()
	version = lines[2].split(' ')[1].rstrip()
	dicoVersion['samtools'] = version

	#Trimmomatic
	dicoVersion['trimmomatic'] = "0.33"

	#GATK
	dicoVersion["GATK"] = "v3.4-0-g7e26428" 

	#SnpSift
	dicoVersion["SnpSift"] = "4.1g" 

	os.system("rm " + tmpFile)

	return dicoVersion


#main function	
def main():	


	##################### gets arguments #####################
	parser=get_parser()
	
	#print parser.help if no arguments
	if len(sys.argv)==1:
		parser.print_help()
		sys.exit(1)
	
	Arguments=parser.parse_args()

	logFile = open(Arguments.logFile, "r")
	logLines = logFile.readlines()

	texFile = Arguments.output + "_report.tex"

	texHeader(texFile)

	tex = open(texFile,'a')
	

	### VarCall command

	tex.write("\section{VarCall command}\n")

	day = logLines[0].split(' ')[0]
	hour = logLines[0].split(' ')[1]

	tex.write("Launched the " + day + " at " + hour + "\n")

	writeVarCallCommand(logLines, tex)

	tex.write("\\\\\n \\\\ \\textbf{Runtime : " + ' '.join(logLines[-1].split(' ')[2:]) + "}\n")


	PREFIX = logLines[6].split(' ')[1]
	PREFIX = PREFIX.rstrip()
	PREFIX = PREFIX.replace("/","{/}")
	PREFIX = PREFIX.replace("_","\_")

	WORKDIR = workdir()

	#tex.write("\\newpage \n")

	tex.write("\section{Trimming and alignment steps}\n")

	tex.write("\subsection{Trimming parameters}\n")

	adaptatersFile = logLines[5].split(' ')[1]
	adaptatersFile = adaptatersFile.rstrip()
	adaptatersFile = adaptatersFile.replace("/","{/}")
	adaptatersFile = adaptatersFile.replace("_","\_")

	TRAILING = logLines[7].split(' ')[1]
	TRAILING = TRAILING.rstrip()

	MINLEN = logLines[8].split(' ')[1]
	MINLEN = MINLEN.rstrip()

	tex.write("Trimming step was performed with Trimmomatic with the following parameters :\n")
	tex.write("\\begin{itemize}\n")
	tex.write("\item ILLUMINACLIP:" + adaptatersFile + ":2:30:15 \n")
	tex.write("\item TRAILING:" + TRAILING + " \n")
	tex.write("\item MINLEN:" + MINLEN + " \n")
	tex.write("\end{itemize}\n")


	tex.write("\subsection{Alignment}\n")

	tex.write("Alignment process was performed with bwa and it default parameters.\
		BAM files can be found at the directory : \\\\"\
		+ "\\textit{" + WORKDIR + "{/}" + PREFIX + "{/}BAM}\n")


	#tex.write("\\newpage \n")
	tex.write("\subsection{Trimming and alignment statistics}\n")

	dicoStats = extractReadStatistics(logLines)

	###### write table 
	tex.write("\\begin {center}\n")
	tex.write("\\begin{tabular}{|l|c|c|c|c|c|c|c|}\n")
	tex.write("\t\hline\n")
	tex.write("\\textbf{genomes} & \\textbf{reads} & \\textbf{trimming} & \\textbf{mapped} & \
		\\textbf{paired} & \\textbf{deep cov.} & \\textbf{breadth cov.} \\\\ \n")
	tex.write("\t\hline\n")

	for element in dicoStats :
		if '/' in element :
			sampleName = element.split('/')[-1]
		else:
			sampleName = element	
		tex.write(sampleName + " & ")
		tex.write(dicoStats[element]["reads"] + " & ")
		tex.write(dicoStats[element]["trimming"] + " & ")
		tex.write(dicoStats[element]["mapped"] + " & ")
		tex.write(dicoStats[element]["paired"] + " & ")

		if(int(dicoStats[element]["deep cov."]) < 20):
			dicoStats[element]["deep cov."] = "\\textcolor{red}{" + \
			dicoStats[element]["deep cov."] + "}"	

		tex.write(dicoStats[element]["deep cov."] + " & ")

		if(float(dicoStats[element]["breadth cov."][0:-2]) < 90.0):
			dicoStats[element]["breadth cov."] = "\\textcolor{red}{" + \
			dicoStats[element]["breadth cov."] + "}"

		tex.write(dicoStats[element]["breadth cov."] + " \\\\ \n")

	tex.write("\t\hline\n")	
	tex.write("\end{tabular}\n")
	tex.write("\end {center}\n")
	######

	#tex.write("\\newpage \n")

	tex.write("\section{Variant calling}\n")

	tex.write("Following an approved framework for variant discovery (DePristo Mark A, 2011), \
		the script VCFmaker SNP and VCFmaker INDEL call and filter variants (i.e. SNPs and \
		InDels) according to GATK best practices (McKenna A, 2010) in order to retain \
		hight-confidence variants (Van der Auwera GA, 2013).\\\\ \\\\  \n")


	tex.write("VCF files for SNPs, InDels and SNPs+InDels merged can be find at the directory : \\\\" \
		+ "\\textit{" + WORKDIR + "{/}" + PREFIX + "{/}VCF}\n")


	tex.write("\section{Matrix and concatenated variants}\n")

	tex.write("Matrix file in tsv (tabular separator value) was made from VCF.\
		This file contain the number of variants per pairwise comparison. \
		This matrix has been generated for SNPs, InDels and SNPs+InDels. \
		\\\\ \\\\ \n")

	tex.write("\
		Matrix files can be find at the directory : \\\\"\
		+ "\\textit{" + WORKDIR + "{/}" + PREFIX + "{/}matrix}\n")

	tex.write(" \\\\ \n")
	tex.write(" \\\\ \n")

	tex.write("Concatenated variants are made from VCF file in FASTA format. \
		You can find concatenated variants for SNPs, InDels and SNPs+InDels at the directory : \\\\"\
		+ "\\textit{" + WORKDIR + "{/}" + PREFIX + "{/}FASTA}\n")

	tex.write(" \\\\ \n")
	tex.write(" \\\\ \n")
	tex.write("The pseudogenome of each sample has also been reconstructed. For each position and \
		for each sample, if the nucleotide doesn't exist in the VCF file, the References nucleotide \
		was been taken. This file can be found in the same FASTA directory.")

	tex.write("\section{Versions}\n")

	dicoVersion = version()
	tex.write("\\begin{itemize}\n")
	for element in dicoVersion :
		tex.write("\item " + element + " : " + dicoVersion[element] + " \n")
	tex.write("\end{itemize}\n")


	tex.write("\section{References}\n")

	tex.write("Li H. and Durbin R. (2009) \\textit{Fast and accurate short read alignment with \
		Burrows-Wheeler Transform.} Bioinformatics, 25:1754-60. [PMID: 19451168]")
	tex.write(" \\\\ \n")
	tex.write(" \\\\ \n")
	tex.write("Li H.*, Handsaker B.*, Wysoker A., Fennell T., Ruan J., Homer N., Marth G., \
		Abecasis G., Durbin R. and 1000 Genome Project Data Processing Subgroup (2009) \\textit{The \
		Sequence alignment/map (SAM) format and SAMtools}. Bioinformatics, 25, 2078-9. \
		[PMID: 19505943] \n")
	tex.write(" \\\\ \n")
	tex.write(" \\\\ \n")
	tex.write("Bolger, A.M., Lohse, M., \& Usadel, B. (2014). \\textit{Trimmomatic: A flexible trimmer \
		for Illumina Sequence Data.} Bioinformatics, btu170.\n")
	tex.write(" \\\\ \n")
	tex.write(" \\\\ \n")
	tex.write("McKenna A, Hanna M, Banks E, Sivachenko A, Cibulskis K, Kernytsky A, Garimella K, \
		Altshuler D, Gabriel S, Daly M, DePristo MA (2010). \\textit{The Genome Analysis Toolkit: a \
		MapReduce framework for analyzing next-generation DNA sequencing data.} Genome Research \
		20:1297-303. \n")
	tex.write(" \\\\ \n")
	tex.write(" \\\\ \n")
	tex.write("Cingolani, P. and Patel, V.M. and Coon, M. and Nguyen, T. and Land, S.J. \
		and Ruden, D.M. and Lu, X. (2012). \\textit{Using Drosophila melanogaster as a model for genotoxic \
		chemical mutational studies with a new program, SnpSift.} Frontiers in Genetics. \n")
	tex.write(" \\\\ \n")
	tex.write(" \\\\ \n")
	tex.write("McKenna A, Hanna M, Banks E, Sivachenko A, Cibulskis K, Kernytsky A, et al. \
		\\textit{The Genome Analysis Toolkit: a MapReduce framework for analyzing next-generation \
		DNA sequencing data.} Genome Res. 2010;20:1297–303. \n")
	tex.write(" \\\\ \n")
	tex.write(" \\\\ \n")
	tex.write("Van der Auwera GA, Carneiro MO, Hartl C, Poplin R, del Angel G, Levy-Moonshine A, \
		et al. From FastQ Data to High-Confidence Variant Calls: The Genome Analysis Toolkit Best \
		Practices Pipeline: The Genome Analysis Toolkit Best Practices Pipeline. In: Bateman A, \
		Pearson WR, Stein LD, Stormo GD, Yates JR, editors. Curr. Protoc. Bioinforma. [Internet]. \
		Hoboken, NJ, USA: John Wiley and Sons, Inc.; 2013 [cited 2016 Oct 24]. p. 11.10.1–11.10.33. \
		Available from: http://doi.wiley.com/10.1002/0471250953.bi1110s43. \n")
	tex.write(" \\\\ \n")
	tex.write(" \\\\ \n")
	tex.write("DePristo Mark A et al. (2011). \\textit{A framework for variation discovery and \
		genotyping using next-generation DNA sequencing data.} Nature Genetics \
		(doi:10.1038/ng.806).\n \\\\ \\\\")

	tex.write("\end{document}")
	tex.close()

	# make pdf
	cmd = "pdflatex "
	if("/" in texFile):
		outputDirectory = texFile.split('/')[0:-1]
		outputDirectory = '/'.join(outputDirectory)
		cmd = cmd + " -output-directory=" + outputDirectory + " "
	cmd = cmd + texFile	
	os.system(cmd)

	texPrefix = texFile.split('.')[0]
	os.system("cat " + texPrefix + ".log >> " + Arguments.output + ".log")
	os.system("rm " + texPrefix + ".aux " + texPrefix + ".log " + texPrefix + ".out " + texPrefix + \
		".tex")



if __name__ == "__main__":
	main()	        		
